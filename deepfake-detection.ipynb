{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-31T17:34:45.383035Z",
     "iopub.status.busy": "2024-08-31T17:34:45.382657Z",
     "iopub.status.idle": "2024-08-31T17:34:45.387824Z",
     "shell.execute_reply": "2024-08-31T17:34:45.386861Z",
     "shell.execute_reply.started": "2024-08-31T17:34:45.382984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:34:45.390003Z",
     "iopub.status.busy": "2024-08-31T17:34:45.389638Z",
     "iopub.status.idle": "2024-08-31T17:34:51.539569Z",
     "shell.execute_reply": "2024-08-31T17:34:51.538515Z",
     "shell.execute_reply.started": "2024-08-31T17:34:45.389881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install Pillow \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:34:51.543331Z",
     "iopub.status.busy": "2024-08-31T17:34:51.542938Z",
     "iopub.status.idle": "2024-08-31T17:34:57.698757Z",
     "shell.execute_reply": "2024-08-31T17:34:57.697929Z",
     "shell.execute_reply.started": "2024-08-31T17:34:51.543263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install facenet_pytorch==2.5.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:34:57.701551Z",
     "iopub.status.busy": "2024-08-31T17:34:57.701277Z",
     "iopub.status.idle": "2024-08-31T17:35:07.591435Z",
     "shell.execute_reply": "2024-08-31T17:35:07.590449Z",
     "shell.execute_reply.started": "2024-08-31T17:34:57.701507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "conda update seaborn statsmodels joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:35:07.593616Z",
     "iopub.status.busy": "2024-08-31T17:35:07.593318Z",
     "iopub.status.idle": "2024-08-31T17:35:07.612886Z",
     "shell.execute_reply": "2024-08-31T17:35:07.611969Z",
     "shell.execute_reply.started": "2024-08-31T17:35:07.593563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm_notebook\n",
    "%matplotlib inline \n",
    "# from google.colab.patches import cv2_imshow\n",
    "from IPython.display import HTML #imports to play videos\n",
    "from base64 import b64encode \n",
    "import cv2 as cv\n",
    "from skimage.measure import compare_ssim\n",
    "import glob\n",
    "import time\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, extract_face\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import skimage.measure\n",
    "import albumentations as A\n",
    "from tqdm.notebook import tqdm \n",
    "from albumentations.pytorch import ToTensor \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models.video import mc3_18, r2plus1d_18\n",
    "\n",
    "from facenet_pytorch import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:35:07.614767Z",
     "iopub.status.busy": "2024-08-31T17:35:07.614433Z",
     "iopub.status.idle": "2024-08-31T17:35:13.938588Z",
     "shell.execute_reply": "2024-08-31T17:35:13.937562Z",
     "shell.execute_reply.started": "2024-08-31T17:35:07.614702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:35:13.940911Z",
     "iopub.status.busy": "2024-08-31T17:35:13.940600Z",
     "iopub.status.idle": "2024-08-31T17:36:03.509270Z",
     "shell.execute_reply": "2024-08-31T17:36:03.508496Z",
     "shell.execute_reply.started": "2024-08-31T17:35:13.940854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the metadata from the uploaded file\n",
    "metadata_path = '/kaggle/input/metadata2/metadata.json'  # Update this to your specific metadata path\n",
    "\n",
    "with open(metadata_path) as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Define the path to the videos in Kaggle's input directory\n",
    "videos_dir = '/kaggle/input/deepfake-detection-videos/All_Videos'  # Update this to your specific dataset folder name\n",
    "\n",
    "# Separate FAKE and REAL videos\n",
    "X = []  # Video filenames\n",
    "y = []  # Labels\n",
    "\n",
    "# Store unique original videos to avoid duplicates\n",
    "originals_seen = set()\n",
    "\n",
    "for video, details in metadata.items():\n",
    "    video_path = os.path.join(videos_dir, video)\n",
    "    if os.path.exists(video_path):  # Ensure the video file exists in the dataset\n",
    "        if details['label'] == 'FAKE' and details['original'] not in originals_seen:\n",
    "            X.append(video_path)\n",
    "            y.append(0)  # Label 0 for FAKE\n",
    "            originals_seen.add(details['original'])\n",
    "        elif details['label'] == 'REAL' and video not in originals_seen:\n",
    "            X.append(video_path)\n",
    "            y.append(1)  # Label 1 for REAL\n",
    "            originals_seen.add(video)\n",
    "\n",
    "# Convert to numpy arrays for compatibility with imbalanced-learn\n",
    "X = np.array(X).reshape(-1, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "# Apply Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Convert back to list for further processing\n",
    "X_resampled = X_resampled.flatten().tolist()\n",
    "\n",
    "# Optionally split into train/validation\n",
    "train_videos, val_videos, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the final lists if needed\n",
    "os.makedirs('/kaggle/working', exist_ok=True)\n",
    "with open('/kaggle/working/train_videos.json', 'w') as f:\n",
    "    json.dump(train_videos, f)\n",
    "    \n",
    "with open('/kaggle/working/val_videos.json', 'w') as f:\n",
    "    json.dump(val_videos, f)\n",
    "\n",
    "print(f\"Train set size: {len(train_videos)}, Validation set size: {len(val_videos)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:58:11.360530Z",
     "iopub.status.busy": "2024-08-31T17:58:11.360247Z",
     "iopub.status.idle": "2024-08-31T17:58:11.365741Z",
     "shell.execute_reply": "2024-08-31T17:58:11.364760Z",
     "shell.execute_reply.started": "2024-08-31T17:58:11.360490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../input/deepfake-detection-challenge\" \n",
    "DATA_FOLDER2 = \"/kaggle/input/deep-fake-detection-dfd-entire-original-dataset\" \n",
    "TRAIN_SAMPLE_FOLDER = \"/kaggle/input/deep-fake-detection-dfd-entire-original-dataset\"\n",
    "TEST_FOLDER = \"test_videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:58:53.230639Z",
     "iopub.status.busy": "2024-08-31T17:58:53.230353Z",
     "iopub.status.idle": "2024-08-31T17:58:53.243492Z",
     "shell.execute_reply": "2024-08-31T17:58:53.242447Z",
     "shell.execute_reply.started": "2024-08-31T17:58:53.230597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_list = list(os.listdir(os.path.join(DATA_FOLDER2, TRAIN_SAMPLE_FOLDER)))\n",
    "ext_dict = []\n",
    "for file in train_list:\n",
    "    file_ext = file.split('.')[1]\n",
    "    if (file_ext not in ext_dict):\n",
    "        ext_dict.append(file_ext)\n",
    "print(f\"Extensions: {ext_dict}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:03.577596Z",
     "iopub.status.busy": "2024-08-31T17:36:03.577361Z",
     "iopub.status.idle": "2024-08-31T17:36:03.582186Z",
     "shell.execute_reply": "2024-08-31T17:36:03.581443Z",
     "shell.execute_reply.started": "2024-08-31T17:36:03.577558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FACE_DETECTION_FOLDER = '../input/haarcascades'\n",
    "print(f\"Face detection resources: {os.listdir(FACE_DETECTION_FOLDER)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:03.584266Z",
     "iopub.status.busy": "2024-08-31T17:36:03.583891Z",
     "iopub.status.idle": "2024-08-31T17:36:03.592221Z",
     "shell.execute_reply": "2024-08-31T17:36:03.591499Z",
     "shell.execute_reply.started": "2024-08-31T17:36:03.584198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_list = list(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))\n",
    "ext_dict = []\n",
    "for file in test_list:\n",
    "    file_ext = file.split('.')[1]\n",
    "    if (file_ext not in ext_dict):\n",
    "        ext_dict.append(file_ext)\n",
    "print(f\"Extensions: {ext_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:03.598294Z",
     "iopub.status.busy": "2024-08-31T17:36:03.598038Z",
     "iopub.status.idle": "2024-08-31T17:36:18.062041Z",
     "shell.execute_reply": "2024-08-31T17:36:18.061304Z",
     "shell.execute_reply.started": "2024-08-31T17:36:03.598244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "json_file = '/kaggle/input/metadata2/metadata.json'\n",
    "print(f\"JSON file: {json_file}\")\n",
    "#reading the json file\n",
    "def get_meta_from_json(path):\n",
    "    df = pd.read_json(os.path.join(DATA_FOLDER, path, json_file))\n",
    "    df = df.T\n",
    "    return df\n",
    "\n",
    "meta_train_df = get_meta_from_json('/kaggle/input/metadata2/metadata.json')\n",
    "meta_train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.066911Z",
     "iopub.status.busy": "2024-08-31T17:36:18.066627Z",
     "iopub.status.idle": "2024-08-31T17:36:18.074317Z",
     "shell.execute_reply": "2024-08-31T17:36:18.073446Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.066849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.075783Z",
     "iopub.status.busy": "2024-08-31T17:36:18.075559Z",
     "iopub.status.idle": "2024-08-31T17:36:18.126618Z",
     "shell.execute_reply": "2024-08-31T17:36:18.125946Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.075745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "missing_data(meta_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.128149Z",
     "iopub.status.busy": "2024-08-31T17:36:18.127923Z",
     "iopub.status.idle": "2024-08-31T17:36:18.154665Z",
     "shell.execute_reply": "2024-08-31T17:36:18.153963Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.128112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "missing_data(meta_train_df.loc[meta_train_df.label == 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.156184Z",
     "iopub.status.busy": "2024-08-31T17:36:18.155962Z",
     "iopub.status.idle": "2024-08-31T17:36:18.162287Z",
     "shell.execute_reply": "2024-08-31T17:36:18.161508Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.156147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def unique_values(data):\n",
    "    total = data.count()\n",
    "    tt = pd.DataFrame(total)\n",
    "    tt.columns = ['Totals']\n",
    "    uniques = []\n",
    "    for col in data.columns:\n",
    "        unique = data[col].nunique() #collect all unique instances\n",
    "        uniques.append(unique)\n",
    "    tt['Uniques'] = uniques\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.163772Z",
     "iopub.status.busy": "2024-08-31T17:36:18.163552Z",
     "iopub.status.idle": "2024-08-31T17:36:18.206735Z",
     "shell.execute_reply": "2024-08-31T17:36:18.206059Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.163729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unique_values(meta_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.208359Z",
     "iopub.status.busy": "2024-08-31T17:36:18.208147Z",
     "iopub.status.idle": "2024-08-31T17:36:18.216550Z",
     "shell.execute_reply": "2024-08-31T17:36:18.215683Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.208324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def most_frequent_values(data):\n",
    "    total = data.count()\n",
    "    tt = pd.DataFrame(total)\n",
    "    tt.columns = ['Total']\n",
    "    items = []\n",
    "    vals = []\n",
    "    for col in data.columns:\n",
    "        itm = data[col].value_counts().index[0]\n",
    "        val = data[col].value_counts().values[0]\n",
    "        items.append(itm)\n",
    "        vals.append(val)\n",
    "    tt['Most frequent item'] = items\n",
    "    tt['Frequence'] = vals\n",
    "    tt['Percent from total'] = np.round(vals / total * 100, 3)\n",
    "    return(np.transpose(tt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.218193Z",
     "iopub.status.busy": "2024-08-31T17:36:18.217864Z",
     "iopub.status.idle": "2024-08-31T17:36:18.313733Z",
     "shell.execute_reply": "2024-08-31T17:36:18.312817Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.218139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "most_frequent_values(meta_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.315560Z",
     "iopub.status.busy": "2024-08-31T17:36:18.315291Z",
     "iopub.status.idle": "2024-08-31T17:36:18.405635Z",
     "shell.execute_reply": "2024-08-31T17:36:18.404781Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.315499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "most_frequent_values(meta_train_df.loc[meta_train_df.label == 'FAKE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.407252Z",
     "iopub.status.busy": "2024-08-31T17:36:18.407022Z",
     "iopub.status.idle": "2024-08-31T17:36:18.416548Z",
     "shell.execute_reply": "2024-08-31T17:36:18.415816Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.407214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_count(feature, title, df, size=1):\n",
    "  '''\n",
    "    Plot count of classes / feature\n",
    "    param: feature - the feature to analyze\n",
    "    param: title - title to add to the graph\n",
    "    param: df - dataframe from which we plot feature's classes distribution \n",
    "    param: size - default 1.\n",
    "  '''  \n",
    "  f, ax = plt.subplots(1,1, figsize=(4*size,4))\n",
    "  total = float(len(df))\n",
    "  g =  sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n",
    "  g.set_title(\"Number and percentage of {}\".format(title)) \n",
    "  if(size > 2):\n",
    "    plt.xticks(rotation=90, size=8)\n",
    "  for p in ax.patches:\n",
    "     height = p.get_height()\n",
    "     ax.text(p.get_x()+ p.get_width()/2.,height + 3,'{:1.2f}%'.format(100*height/total),ha=\"center\")\n",
    "\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.418207Z",
     "iopub.status.busy": "2024-08-31T17:36:18.417924Z",
     "iopub.status.idle": "2024-08-31T17:36:18.659234Z",
     "shell.execute_reply": "2024-08-31T17:36:18.658089Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.418159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_count('split','split(train)',meta_train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.662803Z",
     "iopub.status.busy": "2024-08-31T17:36:18.661731Z",
     "iopub.status.idle": "2024-08-31T17:36:18.924058Z",
     "shell.execute_reply": "2024-08-31T17:36:18.923212Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.662720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_count('label','label(train)',meta_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:18.925847Z",
     "iopub.status.busy": "2024-08-31T17:36:18.925397Z",
     "iopub.status.idle": "2024-08-31T17:36:19.066286Z",
     "shell.execute_reply": "2024-08-31T17:36:19.065491Z",
     "shell.execute_reply.started": "2024-08-31T17:36:18.925796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "meta = np.array(list(meta_train_df.index))\n",
    "storage = np.array([file for file in train_list if  file.endswith('mp4')])\n",
    "print(f\"Metadata: {meta.shape[0]}, Folder: {storage.shape[0]}\")\n",
    "print(f\"Files in metadata and not in folder: {np.setdiff1d(meta,storage,assume_unique=False).shape[0]}\")\n",
    "print(f\"Files in folder and not in metadata: {np.setdiff1d(storage,meta,assume_unique=False).shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:19.068160Z",
     "iopub.status.busy": "2024-08-31T17:36:19.067873Z",
     "iopub.status.idle": "2024-08-31T17:36:19.087048Z",
     "shell.execute_reply": "2024-08-31T17:36:19.086242Z",
     "shell.execute_reply.started": "2024-08-31T17:36:19.068111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fake_train_sample_video = list(meta_train_df.loc[meta_train_df.label=='FAKE'].sample(3).index)\n",
    "fake_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:19.088838Z",
     "iopub.status.busy": "2024-08-31T17:36:19.088536Z",
     "iopub.status.idle": "2024-08-31T17:36:19.095397Z",
     "shell.execute_reply": "2024-08-31T17:36:19.094739Z",
     "shell.execute_reply.started": "2024-08-31T17:36:19.088787Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_image_from_video(video_path):\n",
    "    '''\n",
    "    input: video_path - path for video\n",
    "    process:\n",
    "    1. perform a video capture from the video\n",
    "    2. read the image\n",
    "    3. display the image\n",
    "    '''\n",
    "    capture_img = cv.VideoCapture(video_path)\n",
    "    ret, frame = capture_img.read()\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    ax.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:19.096622Z",
     "iopub.status.busy": "2024-08-31T17:36:19.096373Z",
     "iopub.status.idle": "2024-08-31T17:36:20.777733Z",
     "shell.execute_reply": "2024-08-31T17:36:20.776852Z",
     "shell.execute_reply.started": "2024-08-31T17:36:19.096581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for video_file in fake_train_sample_video:\n",
    "  display_image_from_video(os.path.join(DATA_FOLDER,TRAIN_SAMPLE_FOLDER,video_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:20.779864Z",
     "iopub.status.busy": "2024-08-31T17:36:20.779487Z",
     "iopub.status.idle": "2024-08-31T17:36:20.798013Z",
     "shell.execute_reply": "2024-08-31T17:36:20.797319Z",
     "shell.execute_reply.started": "2024-08-31T17:36:20.779775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "real_train_sample_video = list(meta_train_df.loc[meta_train_df.label=='REAL'].sample(3).index) #viewing the real videos\n",
    "real_train_sample_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:20.799716Z",
     "iopub.status.busy": "2024-08-31T17:36:20.799447Z",
     "iopub.status.idle": "2024-08-31T17:36:22.163449Z",
     "shell.execute_reply": "2024-08-31T17:36:22.162581Z",
     "shell.execute_reply.started": "2024-08-31T17:36:20.799666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for video in real_train_sample_video:\n",
    "  display_image_from_video(os.path.join(DATA_FOLDER,TRAIN_SAMPLE_FOLDER,video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:22.166193Z",
     "iopub.status.busy": "2024-08-31T17:36:22.165415Z",
     "iopub.status.idle": "2024-08-31T17:36:22.178152Z",
     "shell.execute_reply": "2024-08-31T17:36:22.177230Z",
     "shell.execute_reply.started": "2024-08-31T17:36:22.166134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_image_from_video_list(video_path_list, video_folder=TRAIN_SAMPLE_FOLDER):\n",
    "    '''\n",
    "    input: video_path_list - path for video\n",
    "    process:\n",
    "    0. for each video in the video path list\n",
    "        1. perform a video capture from the video\n",
    "        2. read the image\n",
    "        3. display the image\n",
    "    '''\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,3,figsize=(16,8))\n",
    "    #we only show images extracted from first 6 videos\n",
    "    for i, video_file in enumerate(video_path_list[0:6]):\n",
    "      video_path = os.path.join(DATA_FOLDER, video_folder, video_file)\n",
    "      capture_img = cv.VideoCapture(video_path)\n",
    "      ret, frame = capture_img.read()\n",
    "      frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "      ax[i//3, i%3].imshow(frame)\n",
    "      ax[i//3, i%3].set_title(f\"Video: {video_file}\")\n",
    "      ax[i//3, i%3].axis('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:22.179737Z",
     "iopub.status.busy": "2024-08-31T17:36:22.179439Z",
     "iopub.status.idle": "2024-08-31T17:36:23.533591Z",
     "shell.execute_reply": "2024-08-31T17:36:23.532555Z",
     "shell.execute_reply.started": "2024-08-31T17:36:22.179681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "same_original_fake_train_sample_video = list(meta_train_df.loc[meta_train_df.original=='aabdnomlru.mp4'].index)\n",
    "display_image_from_video_list(same_original_fake_train_sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:23.536265Z",
     "iopub.status.busy": "2024-08-31T17:36:23.535580Z",
     "iopub.status.idle": "2024-08-31T17:36:27.978247Z",
     "shell.execute_reply": "2024-08-31T17:36:27.977352Z",
     "shell.execute_reply.started": "2024-08-31T17:36:23.536197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!tar xvf /kaggle/input/ffmpeg-static-build/ffmpeg-git-amd64-static.tar.xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:27.980395Z",
     "iopub.status.busy": "2024-08-31T17:36:27.980099Z",
     "iopub.status.idle": "2024-08-31T17:36:27.991238Z",
     "shell.execute_reply": "2024-08-31T17:36:27.990181Z",
     "shell.execute_reply.started": "2024-08-31T17:36:27.980340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, shutil\n",
    "import timeit, os, gc\n",
    "import subprocess as sp\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import json\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:38:25.159405Z",
     "iopub.status.busy": "2024-08-31T17:38:25.159076Z",
     "iopub.status.idle": "2024-08-31T17:38:25.166842Z",
     "shell.execute_reply": "2024-08-31T17:38:25.165924Z",
     "shell.execute_reply.started": "2024-08-31T17:38:25.159360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HOME = \"./\"\n",
    "FFMPEG = \"/kaggle/working/ffmpeg-git-20191209-amd64-static\"\n",
    "FFMPEG_PATH = FFMPEG\n",
    "DATA_FOLDER = \"/kaggle/input/deepfake-detection-videos\"\n",
    "TMP_FOLDER = HOME\n",
    "DATA_FOLDER_TRAIN = DATA_FOLDER\n",
    "VIDEOS_FOLDER_TRAIN = DATA_FOLDER_TRAIN + \"/All_Videos\"\n",
    "IMAGES_FOLDER_TRAIN = TMP_FOLDER + \"/images\"\n",
    "AUDIOS_FOLDER_TRAIN = TMP_FOLDER + \"/audios\"\n",
    "EXTRACT_META = True # False\n",
    "EXTRACT_CONTENT = True # False\n",
    "EXTRACT_FACES = True # False\n",
    "FRAME_RATE = 0.5 # Frame per\n",
    "print(FFMPEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:28.003957Z",
     "iopub.status.busy": "2024-08-31T17:36:28.003571Z",
     "iopub.status.idle": "2024-08-31T17:36:34.237200Z",
     "shell.execute_reply": "2024-08-31T17:36:34.236249Z",
     "shell.execute_reply.started": "2024-08-31T17:36:28.003886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install imageio-ffmpeg==0.4.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:34.239409Z",
     "iopub.status.busy": "2024-08-31T17:36:34.239097Z",
     "iopub.status.idle": "2024-08-31T17:36:34.285400Z",
     "shell.execute_reply": "2024-08-31T17:36:34.284538Z",
     "shell.execute_reply.started": "2024-08-31T17:36:34.239354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import imageio_ffmpeg as ffmpeg\n",
    "print(ffmpeg.get_ffmpeg_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:34.287719Z",
     "iopub.status.busy": "2024-08-31T17:36:34.287407Z",
     "iopub.status.idle": "2024-08-31T17:36:34.719444Z",
     "shell.execute_reply": "2024-08-31T17:36:34.718491Z",
     "shell.execute_reply.started": "2024-08-31T17:36:34.287656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_command(*popenargs, **kwargs):\n",
    "    closeNULL = 0\n",
    "    try:\n",
    "        from subprocess import DEVNULL\n",
    "        closeNULL = 0\n",
    "    except ImportError:\n",
    "        import os\n",
    "        DEVNULL = open(os.devnull, 'wb')\n",
    "        closeNULL = 1\n",
    "\n",
    "    process = sp.Popen(stdout=sp.PIPE, stderr=DEVNULL, *popenargs, **kwargs)\n",
    "    output, unused_err = process.communicate()\n",
    "    retcode = process.poll()\n",
    "\n",
    "    if closeNULL:\n",
    "        DEVNULL.close()\n",
    "\n",
    "    if retcode:\n",
    "        cmd = kwargs.get(\"args\")\n",
    "        if cmd is None:\n",
    "            cmd = popenargs[0]\n",
    "        error = sp.CalledProcessError(retcode, cmd)\n",
    "        error.output = output\n",
    "        raise error\n",
    "    return output\n",
    "\n",
    "def ffprobe(filename, options = [\"-show_error\", \"-show_format\", \"-show_streams\", \"-show_programs\", \"-show_chapters\", \"-show_private_data\"]):\n",
    "    ret = {}\n",
    "    command = [FFMPEG_PATH + \"/ffprobe\", \"-v\", \"error\", *options, \"-print_format\", \"json\", filename]\n",
    "    ret = run_command(command)\n",
    "    if ret:\n",
    "        ret = json.loads(ret)\n",
    "    return ret\n",
    "\n",
    "# ffmpeg -i input.mov -r 0.25 output_%04d.png\n",
    "def ffextract_frames(filename, output_folder, rate = 0.25):\n",
    "    command = [FFMPEG_PATH + \"/ffmpeg\", \"-i\", filename, \"-r\", str(rate), \"-y\", output_folder + \"/output_%04d.png\"]\n",
    "    ret = run_command(command)\n",
    "    return ret\n",
    "\n",
    "# ffmpeg -i input-video.mp4 output-audio.mp3\n",
    "def ffextract_audio(filename, output_path):\n",
    "    command = [FFMPEG_PATH + \"/ffmpeg\", \"-i\", filename, \"-vn\", \"-ac\", \"1\", \"-acodec\", \"copy\", \"-y\", output_path]\n",
    "    ret = run_command(command)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:36:34.721206Z",
     "iopub.status.busy": "2024-08-31T17:36:34.720873Z",
     "iopub.status.idle": "2024-08-31T17:36:34.737563Z",
     "shell.execute_reply": "2024-08-31T17:36:34.736632Z",
     "shell.execute_reply.started": "2024-08-31T17:36:34.721154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import json\n",
    "import os\n",
    "\n",
    "FFMPEG_PATH = \"/kaggle/working/ffmpeg-git-20191209-amd64-static\"\n",
    "\n",
    "def run_command(*popenargs, **kwargs):\n",
    "    closeNULL = 0\n",
    "    try:\n",
    "        from subprocess import DEVNULL\n",
    "        closeNULL = 0\n",
    "    except ImportError:\n",
    "        import os\n",
    "        DEVNULL = open(os.devnull, 'wb')\n",
    "        closeNULL = 1\n",
    "\n",
    "    process = sp.Popen(stdout=sp.PIPE, stderr=DEVNULL, *popenargs, **kwargs)\n",
    "    output, unused_err = process.communicate()\n",
    "    retcode = process.poll()\n",
    "\n",
    "    if closeNULL:\n",
    "        DEVNULL.close()\n",
    "\n",
    "    if retcode:\n",
    "        cmd = kwargs.get(\"args\", popenargs[0] if popenargs else None)\n",
    "        error = sp.CalledProcessError(retcode, cmd)\n",
    "        error.output = output\n",
    "        raise error\n",
    "    return output\n",
    "\n",
    "def ffprobe(filename, options=None):\n",
    "    if options is None:\n",
    "        options = [\"-show_error\", \"-show_format\", \"-show_streams\", \"-show_programs\", \"-show_chapters\", \"-show_private_data\"]\n",
    "    command = [FFMPEG_PATH + \"/ffprobe\", \"-v\", \"error\", *options, \"-print_format\", \"json\", filename]\n",
    "    ret = run_command(command)\n",
    "    if ret:\n",
    "        ret = json.loads(ret)\n",
    "    return ret\n",
    "\n",
    "def ffextract_frames(filename, output_folder, rate=0.25):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    command = [FFMPEG_PATH + \"/ffmpeg\", \"-i\", filename, \"-r\", str(rate), \"-y\", os.path.join(output_folder, \"output_%04d.png\")]\n",
    "    ret = run_command(command)\n",
    "    return ret\n",
    "\n",
    "def ffextract_audio(filename, output_path):\n",
    "    command = [FFMPEG_PATH + \"/ffmpeg\", \"-i\", filename, \"-vn\", \"-ac\", \"1\", \"-acodec\", \"copy\", \"-y\", output_path]\n",
    "    ret = run_command(command)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:38:48.005280Z",
     "iopub.status.busy": "2024-08-31T17:38:48.004940Z",
     "iopub.status.idle": "2024-08-31T17:38:48.047490Z",
     "shell.execute_reply": "2024-08-31T17:38:48.046077Z",
     "shell.execute_reply.started": "2024-08-31T17:38:48.005223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "subfolder = DATA_FOLDER_TRAIN + \"/All_Videos\"  # Replace with the correct path\n",
    "print(f\"Looking for files in: {subfolder}\")\n",
    "\n",
    "if os.path.isdir(subfolder):\n",
    "    all_files = os.listdir(subfolder)\n",
    "    print(f\"All files in directory: {all_files}\")\n",
    "else:\n",
    "    print(f\"Directory does not exist: {subfolder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T17:42:39.189479Z",
     "iopub.status.busy": "2024-08-31T17:42:39.189120Z",
     "iopub.status.idle": "2024-08-31T17:42:40.339748Z",
     "shell.execute_reply": "2024-08-31T17:42:40.338341Z",
     "shell.execute_reply.started": "2024-08-31T17:42:39.189420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if EXTRACT_META == True:\n",
    "    results = []\n",
    "    subfolder = VIDEOS_FOLDER_TRAIN\n",
    "    filepaths = glob.glob(subfolder + \"/*.mp4\")\n",
    "    for filepath in tqdm(filepaths):\n",
    "        js = ffprobe(filepath)\n",
    "#        print(js)\n",
    "        if js:\n",
    "            results.append(\n",
    "                (js.get(\"format\", {}).get(\"filename\")[len(subfolder) + 1:],\n",
    "                js.get(\"format\", {}).get(\"format_long_name\"),\n",
    "                # Video \n",
    "                js.get(\"streams\", [{}, {}])[0].get(\"codec_name\"),\n",
    "                js.get(\"streams\", [{}, {}])[0].get(\"height\"),\n",
    "                js.get(\"streams\", [{}, {}])[0].get(\"width\"),\n",
    "                js.get(\"streams\", [{}, {}])[0].get(\"nb_frames\"),\n",
    "                js.get(\"streams\", [{}, {}])[0].get(\"bit_rate\"),\n",
    "                js.get(\"streams\", [{}, {}])[0].get(\"duration\"),\n",
    "                js.get(\"streams\", [{}, {}])[0].get(\"start_time\"),\n",
    "                js.get(\"streams\", [{}, {}])[0].get(\"avg_frame_rate\"),\n",
    "                 # Audio\n",
    "                js.get(\"streams\", [{}, {}])[1].get(\"codec_name\"),\n",
    "                js.get(\"streams\", [{}, {}])[1].get(\"channels\"),\n",
    "                js.get(\"streams\", [{}, {}])[1].get(\"sample_rate\"),\n",
    "                js.get(\"streams\", [{}, {}])[1].get(\"nb_frames\"),\n",
    "                js.get(\"streams\", [{}, {}])[1].get(\"bit_rate\"),\n",
    "                js.get(\"streams\", [{}, {}])[1].get(\"duration\"),\n",
    "                js.get(\"streams\", [{}, {}])[1].get(\"start_time\")),\n",
    "            )\n",
    "\n",
    "    meta_pd = pd.DataFrame(results, columns=[\"filename\", \"format\", \"video_codec_name\", \"video_height\", \"video_width\",\n",
    "                                            \"video_nb_frames\", \"video_bit_rate\", \"video_duration\", \"video_start_time\",\"video_fps\",\n",
    "                                            \"audio_codec_name\", \"audio_channels\", \"audio_sample_rate\", \"audio_nb_frames\",\n",
    "                                            \"audio_bit_rate\", \"audio_duration\", \"audio_start_time\"])\n",
    "    meta_pd[\"video_fps\"] = meta_pd[\"video_fps\"].apply(lambda x: float(x.split(\"/\")[0])/float(x.split(\"/\")[1]) if len(x.split(\"/\")) == 2 else None)\n",
    "    meta_pd[\"video_duration\"] = meta_pd[\"video_duration\"].astype(np.float32)\n",
    "    meta_pd[\"video_bit_rate\"] = meta_pd[\"video_bit_rate\"].astype(np.float32)\n",
    "    meta_pd[\"video_start_time\"] = meta_pd[\"video_start_time\"].astype(np.float32)\n",
    "    meta_pd[\"video_nb_frames\"] = meta_pd[\"video_nb_frames\"].astype(np.float32)\n",
    "    meta_pd[\"video_bit_rate\"] = meta_pd[\"video_bit_rate\"].astype(np.float32)\n",
    "    meta_pd[\"audio_sample_rate\"] = meta_pd[\"audio_sample_rate\"].astype(np.float32)\n",
    "    meta_pd[\"audio_nb_frames\"] = meta_pd[\"audio_nb_frames\"].astype(np.float32)\n",
    "    meta_pd[\"audio_bit_rate\"] = meta_pd[\"audio_bit_rate\"].astype(np.float32)\n",
    "    meta_pd[\"audio_duration\"] = meta_pd[\"audio_duration\"].astype(np.float32)\n",
    "    meta_pd[\"audio_start_time\"] = meta_pd[\"audio_start_time\"].astype(np.float32)\n",
    "    meta_pd.to_pickle(HOME + \"videos_meta.pkl\")\n",
    "else:\n",
    "    meta_pd = pd.read_pickle(HOME + \"videos_meta.pkl\")\n",
    "meta_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:42:38.150669Z",
     "iopub.status.idle": "2024-08-31T17:42:38.151259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,6, figsize=(22, 3))\n",
    "d = sns.distplot(meta_pd[\"video_fps\"], ax=ax[0])\n",
    "d = sns.distplot(meta_pd[\"video_duration\"], ax=ax[1])\n",
    "d = sns.distplot(meta_pd[\"video_width\"], ax=ax[2])\n",
    "d = sns.distplot(meta_pd[\"video_height\"], ax=ax[3])\n",
    "d = sns.distplot(meta_pd[\"video_nb_frames\"], ax=ax[4])\n",
    "d = sns.distplot(meta_pd[\"video_bit_rate\"], ax=ax[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.002595Z",
     "iopub.status.idle": "2024-08-31T17:36:36.003974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_pd = pd.read_json(VIDEOS_FOLDER_TRAIN + \"/metadata.json\").T.reset_index().rename(columns={\"index\": \"filename\"})\n",
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.006118Z",
     "iopub.status.idle": "2024-08-31T17:36:36.007378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_pd = pd.read_json(VIDEOS_FOLDER_TRAIN + \"/metadata.json\").T.reset_index().rename(columns={\"index\": \"filename\"})\n",
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.009403Z",
     "iopub.status.idle": "2024-08-31T17:36:36.010666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_pd = pd.merge(train_pd, meta_pd[[\"filename\", \"video_height\", \"video_width\", \"video_nb_frames\", \"video_bit_rate\", \"audio_nb_frames\"]], on=\"filename\", how=\"left\")\n",
    "train_pd[\"count\"] = train_pd.groupby([\"original\"])[\"original\"].transform('count')\n",
    "# train_pd.to_pickle(HOME + \"train_meta.pkl\")\n",
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.012707Z",
     "iopub.status.idle": "2024-08-31T17:36:36.013969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "AUDIO_FORMAT = \"aac\" # \"wav\"\n",
    "videos_folder = VIDEOS_FOLDER_TRAIN\n",
    "images_folder_path = IMAGES_FOLDER_TRAIN\n",
    "audios_folder_path = AUDIOS_FOLDER_TRAIN\n",
    "if EXTRACT_CONTENT == True:\n",
    "    # 1h20min for chunk#0 (11GB)\n",
    "    # Extract some images + audio track\n",
    "    for idx, row in tqdm(train_pd.iterrows(), total=meta_pd.shape[0]):\n",
    "        try:\n",
    "            video_path = videos_folder + \"/\" + row[\"filename\"]\n",
    "            images_path = images_folder_path + \"/\" + row[\"filename\"][:-4]\n",
    "            audio_path = audios_folder_path + \"/\" + row[\"filename\"][:-4]\n",
    "            # Extract images\n",
    "            if not os.path.exists(images_path): os.makedirs(images_path)\n",
    "            ret = ffextract_frames(video_path, images_path, rate = FRAME_RATE)\n",
    "            # Extract audio\n",
    "            if not os.path.exists(audio_path): os.makedirs(audio_path)\n",
    "            # ret = ffextract_audio(video_path, audio_path + \"/audio.\" + AUDIO_FORMAT)\n",
    "        except:\n",
    "            print(\"Cannot extract frames/audio for:\" + row[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.015983Z",
     "iopub.status.idle": "2024-08-31T17:36:36.017230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_pd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.019270Z",
     "iopub.status.idle": "2024-08-31T17:36:36.020599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = 21 # 27 # 21 # 19 # 12 # 6\n",
    "fake = train_pd[\"filename\"][idx]\n",
    "real = train_pd[\"original\"][idx]\n",
    "vid_width = train_pd[\"video_width\"][idx]\n",
    "vid_real = open(VIDEOS_FOLDER_TRAIN + \"/\" + real, 'rb').read()\n",
    "data_url_real = \"data:video/mp4;base64,\" + b64encode(vid_real).decode()\n",
    "vid_fake = open(VIDEOS_FOLDER_TRAIN + \"/\" + fake, 'rb').read()\n",
    "data_url_fake = \"data:video/mp4;base64,\" + b64encode(vid_fake).decode()\n",
    "HTML(\"\"\"\n",
    "<div style='width: 100%%; display: table;'>\n",
    "    <div style='display: table-row'>\n",
    "        <div style='width: %dpx; display: table-cell;'><b>Real</b>: %s<br/><video width=%d controls><source src=\"%s\" type=\"video/mp4\"></video></div>\n",
    "        <div style='display: table-cell;'><b>Fake</b>: %s<br/><video width=%d controls><source src=\"%s\" type=\"video/mp4\"></video></div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\" % ( int(vid_width/3.2) + 10, \n",
    "       real, int(vid_width/3.2), data_url_real, \n",
    "       fake, int(vid_width/3.2), data_url_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.022631Z",
     "iopub.status.idle": "2024-08-31T17:36:36.023878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def detect_face_cv2(img):\n",
    "    # Move to grayscale\n",
    "    gray_img = cv2.cvtColor(img.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    face_locations = []\n",
    "    face_rects = face_cascade.detectMultiScale(gray_img, scaleFactor=1.3, minNeighbors=5)     \n",
    "    for (x,y,w,h) in face_rects: \n",
    "        face_location = (x,y,w,h)\n",
    "        face_locations.append((face_location, 1.0))\n",
    "    return face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.025960Z",
     "iopub.status.idle": "2024-08-31T17:36:36.027040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.028912Z",
     "iopub.status.idle": "2024-08-31T17:36:36.029955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "def detect_face_mtcnn(img):\n",
    "    face_locations = []\n",
    "    items = detector.detect_faces(img)\n",
    "    for face in items:\n",
    "        face_location = tuple(face.get('box'))\n",
    "        face_confidence = float(face.get('confidence'))\n",
    "        face_locations.append((face_location, face_confidence))\n",
    "    return face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.031764Z",
     "iopub.status.idle": "2024-08-31T17:36:36.032817Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_faces(files, source, detector=detect_face_cv2):\n",
    "    results = []\n",
    "    # for idx, file in tqdm(enumerate(files), total=len(files)):\n",
    "    for idx, file in enumerate(files):\n",
    "        try:\n",
    "            img = cv2.cvtColor(cv2.imread(file, cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB)\n",
    "            face_locations = detector(img)\n",
    "            results.append((source, file[file.find(\"output_\"):], face_locations, len(face_locations)))\n",
    "        except:\n",
    "            print(\"Cannot extract faces for image: %s\" % file)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.034678Z",
     "iopub.status.idle": "2024-08-31T17:36:36.035723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file = fake\n",
    "dump_folder = images_folder_path + \"/\" + file[:-4]\n",
    "files = glob.glob(dump_folder + \"/*\")\n",
    "DETECTORS = {\n",
    "    \"cv2\": detect_face_cv2,\n",
    "    \"mtcnn\": detect_face_mtcnn\n",
    "}\n",
    "faces_pd = None\n",
    "for key, value in DETECTORS.items():\n",
    "    tmp_pd = pd.DataFrame(extract_faces(files, file, detector=value), columns=[\"filename\", \"image\", \"boxes_\" + key , \"faces_\" + key])\n",
    "    if faces_pd is None:\n",
    "        faces_pd = tmp_pd\n",
    "    else:\n",
    "        faces_pd = pd.merge(faces_pd, tmp_pd, on=[\"filename\", \"image\"], how=\"left\")\n",
    "faces_pd.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.037586Z",
     "iopub.status.idle": "2024-08-31T17:36:36.038624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_faces_boxes(df, max_cols = 2, max_rows = 6, fsize=(24, 5), max_items=12):    \n",
    "    idx = 0    \n",
    "    for item_idx, item in df.iterrows():\n",
    "        img = cv2.cvtColor(cv2.imread(IMAGES_FOLDER_TRAIN + \"/\" + item[\"filename\"][:-4] +\"/\" + item[\"image\"], cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB)    \n",
    "        face_img = img #.copy()\n",
    "        # grid subplots\n",
    "        row = idx // max_cols\n",
    "        col = idx % max_cols\n",
    "        if col == 0: fig = plt.figure(figsize=fsize)\n",
    "        ax = fig.add_subplot(1, max_cols, col + 1)\n",
    "        ax.axis(\"off\")\n",
    "        # display image with boxes\n",
    "        cols = [c for c in df.columns if \"boxes\" in c]\n",
    "        for i, c in enumerate(cols, 0):\n",
    "            face_locations = item[c]\n",
    "            face_confidence = item[c]            \n",
    "            if len(face_locations) > 0:\n",
    "                for face_location in face_locations:        \n",
    "                    ((x,y,w,h), confidence) = face_location\n",
    "                    # face_img = face_img[y:y+h, x:x+w]\n",
    "                    cv2.rectangle(face_img, (x, y), (x+w, y+h), (255,i*255,0), 8)\n",
    "                    cv2.putText(face_img, '%.1f' % (confidence*100.0), (x+w, y+h), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255,i*255,0), 9, cv2.LINE_AA)\n",
    "                ax.imshow(face_img)\n",
    "            else:\n",
    "                ax.imshow(img)\n",
    "            ax.set_title(\"%s %s / %s - Faces: %d %s %s\" % (item[\"label\"] if \"label\" in df.columns else \"\", \n",
    "                                                           item[\"filename\"], item[\"image\"],\n",
    "                                                           item[\"faces_mtcnn\"] if \"faces_mtcnn\" in df.columns else len(face_locations),\n",
    "                                                           item[\"faces_mtcnn_median\"] if \"faces_mtcnn_median\" in df.columns else \"\",\n",
    "                                                           item[\"faces\"] if \"faces\" in df.columns else \"\"))\n",
    "        if (col == max_cols -1): plt.show()\n",
    "        idx = idx + 1\n",
    "        if (max_items > 0 and idx >=max_items): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.040423Z",
     "iopub.status.idle": "2024-08-31T17:36:36.041463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_faces_boxes(faces_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.043306Z",
     "iopub.status.idle": "2024-08-31T17:36:36.044344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_detector_on_video(videos_filename, verbose=False):\n",
    "    if verbose == True: \n",
    "        print(\"Starting with batch of %d videos\" % len(videos_filename))\n",
    "    tmp_faces_pd = None\n",
    "    for file in videos_filename:\n",
    "        # Find out dump folder with images\n",
    "        dump_folder = images_folder_path + \"/\" + file[:-4]\n",
    "        # List files\n",
    "        files = glob.glob(dump_folder + \"/*\")\n",
    "        DETECTORS = {\n",
    "            \"mtcnn\": detect_face_mtcnn\n",
    "        }\n",
    "        for key, value in DETECTORS.items():\n",
    "            tmp_pd = pd.DataFrame(extract_faces(files, file, detector=value), columns=[\"filename\", \"image\", \"boxes_\" + key , \"faces_\" + key])\n",
    "            if tmp_faces_pd is None:\n",
    "                tmp_faces_pd = tmp_pd\n",
    "            else:\n",
    "                tmp_faces_pd = pd.concat([tmp_faces_pd, tmp_pd], axis=0)\n",
    "    return tmp_faces_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.046176Z",
     "iopub.status.idle": "2024-08-31T17:36:36.047222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cpus = multiprocessing.cpu_count()\n",
    "if EXTRACT_FACES == True:\n",
    "    resultfutures = []\n",
    "    results = []\n",
    "    tasks = np.array_split(train_pd[\"filename\"].unique(), 20)\n",
    "    print(\"Tasks: %d\" % len(tasks))\n",
    "    with ThreadPoolExecutor(max_workers=cpus) as executor:\n",
    "        resultfutures = tqdm(executor.map(run_detector_on_video, tasks), total=len(tasks))\n",
    "    results = [x for x in resultfutures]\n",
    "    executor.shutdown()\n",
    "    # Gather results\n",
    "    all_faces_pd = None\n",
    "    for result in results:\n",
    "        if all_faces_pd is None:\n",
    "            all_faces_pd = result\n",
    "        else:\n",
    "            all_faces_pd = pd.concat([all_faces_pd, result], axis=0)\n",
    "    all_faces_pd = all_faces_pd.reset_index(drop=True)\n",
    "    all_faces_pd.to_pickle(HOME + \"faces.pkl\")\n",
    "else:\n",
    "    all_faces_pd = pd.read_pickle(HOME + \"faces.pkl\")\n",
    "print(all_faces_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.049048Z",
     "iopub.status.idle": "2024-08-31T17:36:36.050099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_faces_pd[\"faces_mtcnn_avg\"] = all_faces_pd.groupby(\"filename\")[\"faces_mtcnn\"].transform(np.nanmean)\n",
    "all_faces_pd[\"faces_mtcnn_median\"] = all_faces_pd.groupby(\"filename\")[\"faces_mtcnn\"].transform(np.nanmedian)\n",
    "all_faces_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.052117Z",
     "iopub.status.idle": "2024-08-31T17:36:36.053194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(22, 3))\n",
    "d = sns.distplot(all_faces_pd[\"faces_mtcnn_avg\"], kde=True, ax=ax[0])\n",
    "d = sns.distplot(all_faces_pd[\"faces_mtcnn_median\"], kde=False, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.055057Z",
     "iopub.status.idle": "2024-08-31T17:36:36.056110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_faces_boxes(all_faces_pd[all_faces_pd[\"faces_mtcnn\"] == 3], max_items=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.057932Z",
     "iopub.status.idle": "2024-08-31T17:36:36.058975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "clean_faces_pd = pd.merge(all_faces_pd, train_pd, on=\"filename\", how=\"left\")\n",
    "clean_faces_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.060867Z",
     "iopub.status.idle": "2024-08-31T17:36:36.062034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def faces_max_item(boxes, idx1, idx2):\n",
    "    ret = 0\n",
    "    if len(boxes) > 0:\n",
    "        ret = max(boxes, key=lambda item: item[idx1][idx2])[idx1][idx2]\n",
    "    return ret\n",
    "\n",
    "def faces_max_confidence(boxes):\n",
    "    ret = 0\n",
    "    if len(boxes) > 0:\n",
    "        ret = max(boxes, key=lambda item: item[1])[1]\n",
    "    return ret\n",
    "\n",
    "def faces_min_confidence(boxes):\n",
    "    ret = 0\n",
    "    if len(boxes) > 0:\n",
    "        ret = min(boxes, key=lambda item: item[1])[1]\n",
    "    return ret\n",
    "\n",
    "clean_faces_pd[\"faces_max_width\"] = clean_faces_pd[\"boxes_mtcnn\"].apply(lambda x: faces_max_item(x, 0, 2)) \n",
    "clean_faces_pd[\"faces_max_height\"] = clean_faces_pd[\"boxes_mtcnn\"].apply(lambda x: faces_max_item(x, 0, 3))\n",
    "clean_faces_pd[\"faces_max_conf\"] = clean_faces_pd[\"boxes_mtcnn\"].apply(lambda x: faces_max_confidence(x))\n",
    "clean_faces_pd[\"faces_min_conf\"] = clean_faces_pd[\"boxes_mtcnn\"].apply(lambda x: faces_min_confidence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.064137Z",
     "iopub.status.idle": "2024-08-31T17:36:36.065197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Faces stats:\")\n",
    "print(clean_faces_pd[[\"faces_max_width\", \"faces_max_height\", \"faces_min_conf\", \"faces_max_conf\"]].describe(percentiles=[0.01,0.05, 0.1,0.25,0.5,0.75,0.9,0.95,0.99]))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(22, 3))\n",
    "d = sns.distplot(clean_faces_pd[\"faces_max_width\"], kde=True, ax=ax[0])\n",
    "d = sns.distplot(clean_faces_pd[\"faces_max_height\"], kde=True, ax=ax[1])\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(22, 3))\n",
    "d = sns.distplot(clean_faces_pd[\"faces_min_conf\"], kde=True, ax=ax[0])\n",
    "d = sns.distplot(clean_faces_pd[\"faces_max_conf\"], kde=True, ax=ax[1])\n",
    "fig, ax = plt.subplots(figsize=(22, 3))\n",
    "d = clean_faces_pd.plot(kind=\"scatter\", x=\"faces_max_width\", y=\"faces_max_conf\", c=\"red\", ax=ax, label=\"faces_max_width\", alpha=0.5)\n",
    "d = clean_faces_pd.plot(kind=\"scatter\", x=\"faces_max_height\", y=\"faces_max_conf\", c=\"blue\", ax=d,  label=\"faces_max_height\", alpha=0.5)\n",
    "d = plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.066995Z",
     "iopub.status.idle": "2024-08-31T17:36:36.068038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.069441Z",
     "iopub.status.idle": "2024-08-31T17:36:36.069818Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from imutils import paths\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.071261Z",
     "iopub.status.idle": "2024-08-31T17:36:36.071770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"/kaggle/working/finetuningkeras/dataset\"\n",
    "\n",
    "# define the names of the training, testing, and validation\n",
    "# directories\n",
    "TRAIN = \"training\"\n",
    "TEST = \"evaluation\"\n",
    "VAL = \"validation\"\n",
    "\n",
    "REAL = 'REAL'\n",
    "FAKE = 'FAKE'\n",
    "\n",
    "# initialize the list of class label names\n",
    "CLASSES = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "\n",
    "# set the batch size when fine-tuning\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "trainEpochs = 10\n",
    "epochsFineTune = 10\n",
    "maxVids = 5\n",
    "\n",
    "# set the path to the serialized model after training\n",
    "MODEL_PATH = os.path.sep.join([\"/kaggle/working/finetuningkeras\",\"output\", \"Deepfake.model\"])\n",
    "MODEL_PATH2 = os.path.sep.join([\"/kaggle/working/finetuningkeras\",\"output\", \"Deepfake2.h5\"])\n",
    "# define the path to the output training history plots\n",
    "UNFROZEN_PLOT_PATH = os.path.sep.join([\"/kaggle/working/finetuningkeras\",\"output\", \"unfrozen.png\"])\n",
    "WARMUP_PLOT_PATH = os.path.sep.join([\"/kaggle/working/finetuningkeras\",\"output\", \"warmup.png\"])\n",
    "\n",
    "file = '/kaggle/input/deepfake-detection-challenge/train_sample_videos/metadata.json'\n",
    "img_path = '/kaggle/input/deepfake-detection-challenge/train_sample_videos'\n",
    "data_path = '/kaggle/working/finetuningkeras/real_fake'\n",
    "dir_fake_frames = '/kaggle/working/FAKE_frames'\n",
    "dir_real_frames = '/kaggle/working/REAL_frames'\n",
    "dir_output = '/kaggle/working/finetuningkeras/output'\n",
    "\n",
    "dir_data_path_real = os.path.join(data_path, REAL)\n",
    "dir_data_path_fake = os.path.join(data_path, FAKE)\n",
    "\n",
    "dir_train_real = os.path.join(BASE_PATH, TRAIN, REAL)\n",
    "dir_train_fake = os.path.join(BASE_PATH, TRAIN, FAKE)\n",
    "dir_valid_real = os.path.join(BASE_PATH, VAL, REAL)\n",
    "dir_valid_fake = os.path.join(BASE_PATH, VAL, FAKE)\n",
    "dir_test_real = os.path.join(BASE_PATH, TEST, REAL)\n",
    "dir_test_fake = os.path.join(BASE_PATH, TEST, FAKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.073179Z",
     "iopub.status.idle": "2024-08-31T17:36:36.073677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/working/finetuningkeras/real_fake/FAKE'\n",
    "output_dir = '/kaggle/working/FAKE_frames/'\n",
    "def explode_frames(input_dir, output_dir, maxN):\n",
    "\n",
    "    mp4_filenames = [f for f in os.listdir(input_dir) if f.endswith('.mp4')]\n",
    "    n = 0\n",
    "    \n",
    "    for mp4fn in mp4_filenames:\n",
    "        \n",
    "        if(n < maxN):\n",
    "            n += 1 \n",
    "            mp4fp = os.path.join(input_dir, mp4fn)\n",
    "            cam = cv2.VideoCapture(mp4fp) \n",
    "            if(cam.isOpened()):\n",
    "                print('Processing file #'+ str(n) + ' (' + mp4fn + ')...')\n",
    "            else: \n",
    "                print('Problem opening file #'+ str(n) + ' (' + mp4fn + ')...')\n",
    "                continue \n",
    "            \n",
    "            nframe = 0\n",
    "            while(True): #continue until ret = False then break\n",
    "                nframe += 1\n",
    "                ret,frame = cam.read()\n",
    "                \n",
    "                if ret: \n",
    "                    # if video is still left continue creating images \n",
    "                    out_filename = os.path.splitext(mp4fn)[0]+  '_frame' + str(nframe) + '.jpg'\n",
    "                    out_filepath =  os.path.join(output_dir, out_filename)\n",
    "                    \n",
    "                    # writing the extracted images \n",
    "                    cv2.imwrite(out_filepath, frame) \n",
    "                else: \n",
    "                    break\n",
    "\n",
    "            # Release all space and windows once done\n",
    "            print(' - created ' + str(nframe-1) + ' images') # -1 bc count incremented before exit\n",
    "            cam.release() \n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "        else: \n",
    "            break\n",
    "            \n",
    "\"\"\"\n",
    "Distribute files/images from a source directory into training, validation, and testing directories. \n",
    "src_dir = source/input directory\n",
    "train_dir, val_dir, test_dir = target training/validation/testing directory\n",
    "valperc = fraction of dataset to use for validation (0-1)\n",
    "testperc = fraction of dataset to use for testing (0-1)\n",
    "\"\"\"\n",
    "            \n",
    "def trainvaltest_split(src_dir, train_dir, val_dir, test_dir, valperc = 0.15, testperc = 0.15):\n",
    "    \n",
    "    filenames = os.listdir(src_dir) #get all filenames in random order\n",
    "    np.random.shuffle(filenames)\n",
    "    \n",
    "    n = len(filenames)\n",
    "    split1 = int(n*(1 - (valperc + testperc)))\n",
    "    split2 = int(n*(1 - (testperc)))\n",
    "    \n",
    "    fn_train, fn_val, fn_test = np.split(np.array(filenames), [split1, split2])\n",
    "    \n",
    "    fn_lists = [fn_train, fn_val, fn_test]\n",
    "    targetdirs = [train_dir, val_dir, test_dir]\n",
    "    \n",
    "    print('Total images: ', n)\n",
    "    print('Training: ', len(fn_train))\n",
    "    print('Validation: ', len(fn_val))\n",
    "    print('Testing: ', len(fn_test))\n",
    "    \n",
    "    all_fp = [os.path.join(src_dir, fn) for fn in filenames]\n",
    "    \n",
    "    #move files\n",
    "    for i, fn_list in enumerate(fn_lists):\n",
    "        for fn in fn_list: \n",
    "            target_dir = targetdirs[i]\n",
    "            fp_from = os.path.join(src_dir, fn)\n",
    "            fp_to = os.path.join(target_dir, fn)\n",
    "            \n",
    "            shutil.move(fp_from, fp_to)\n",
    "\n",
    "            \n",
    "\"\"\"\n",
    "Construct a plot that plots and saves the training history\n",
    "\"\"\"           \n",
    "def plot_training(H, N, plotPath):\n",
    "\tplt.style.use(\"ggplot\")\n",
    "\tplt.figure()\n",
    "\tplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "\tplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\tplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "\tplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\tplt.title(\"Training Loss and Accuracy\")\n",
    "\tplt.xlabel(\"Epoch #\")\n",
    "\tplt.ylabel(\"Loss/Accuracy\")\n",
    "\tplt.legend(loc=\"lower left\")\n",
    "\tplt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.075098Z",
     "iopub.status.idle": "2024-08-31T17:36:36.075658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(dir_train_real, exist_ok = True)\n",
    "os.makedirs(dir_train_fake, exist_ok = True)\n",
    "os.makedirs(dir_valid_real, exist_ok = True)\n",
    "os.makedirs(dir_valid_fake, exist_ok = True)\n",
    "os.makedirs(dir_test_real, exist_ok = True)\n",
    "os.makedirs(dir_test_fake, exist_ok = True)\n",
    "\n",
    "os.makedirs(dir_data_path_real, exist_ok = True)\n",
    "os.makedirs(dir_data_path_fake, exist_ok = True)\n",
    "os.makedirs(dir_fake_frames, exist_ok = True) \n",
    "os.makedirs(dir_real_frames, exist_ok = True) \n",
    "os.makedirs(dir_output, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.077083Z",
     "iopub.status.idle": "2024-08-31T17:36:36.077566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(file)\n",
    "df = df.T\n",
    "\n",
    "# %% [code]\n",
    "label = df[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.078858Z",
     "iopub.status.idle": "2024-08-31T17:36:36.079456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for fn, row in label.iterrows():\n",
    "    src = os.path.join(img_path, fn)\n",
    "    dest = os.path.join(data_path, row['label'], fn)\n",
    "    shutil.copy(src, dest)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.080692Z",
     "iopub.status.idle": "2024-08-31T17:36:36.081142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "explode_frames(dir_data_path_fake, dir_fake_frames, maxN= maxVids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.082428Z",
     "iopub.status.idle": "2024-08-31T17:36:36.082989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "explode_frames(dir_data_path_real, dir_real_frames, maxN= maxVids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.084055Z",
     "iopub.status.idle": "2024-08-31T17:36:36.084531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainvaltest_split(src_dir = dir_fake_frames,\n",
    "                   train_dir = dir_train_fake, \n",
    "                   val_dir = dir_valid_fake, \n",
    "                   test_dir = dir_test_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.085721Z",
     "iopub.status.idle": "2024-08-31T17:36:36.086243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainvaltest_split(src_dir = dir_real_frames,\n",
    "                   train_dir = dir_train_real, \n",
    "                   val_dir = dir_valid_real, \n",
    "                   test_dir = dir_test_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.087611Z",
     "iopub.status.idle": "2024-08-31T17:36:36.088185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "\trotation_range=30,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.089319Z",
     "iopub.status.idle": "2024-08-31T17:36:36.089912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "valAug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.090916Z",
     "iopub.status.idle": "2024-08-31T17:36:36.091452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.092662Z",
     "iopub.status.idle": "2024-08-31T17:36:36.093190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainPath = os.path.join(BASE_PATH, TRAIN)\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\ttrainPath,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BATCH_SIZE)\n",
    "\n",
    "# initialize the validation generator\n",
    "valPath = os.path.join(BASE_PATH, VAL)\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tvalPath,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BATCH_SIZE)\n",
    "\n",
    "# initialize the testing generator\n",
    "testPath = os.path.join(BASE_PATH, TEST)\n",
    "testGen = valAug.flow_from_directory(\n",
    "\ttestPath,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.094127Z",
     "iopub.status.idle": "2024-08-31T17:36:36.094552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.095452Z",
     "iopub.status.idle": "2024-08-31T17:36:36.095838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(CLASSES), activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.097534Z",
     "iopub.status.idle": "2024-08-31T17:36:36.098049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.098970Z",
     "iopub.status.idle": "2024-08-31T17:36:36.099514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.101206Z",
     "iopub.status.idle": "2024-08-31T17:36:36.101588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.102809Z",
     "iopub.status.idle": "2024-08-31T17:36:36.103217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "totalTrain = len(list(paths.list_images(trainPath)))\n",
    "totalVal = len(list(paths.list_images(valPath)))\n",
    "totalTest = len(list(paths.list_images(testPath)))\n",
    "\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    trainGen,\n",
    "    steps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "    validation_data=valGen,\n",
    "    validation_steps=totalVal // BATCH_SIZE,\n",
    "    epochs=trainEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.104151Z",
     "iopub.status.idle": "2024-08-31T17:36:36.104603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating after fine-tuning network head...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(totalTest // BATCH_SIZE) + 1)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "\n",
    "\n",
    "plot_training(H, trainEpochs, WARMUP_PLOT_PATH)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.105535Z",
     "iopub.status.idle": "2024-08-31T17:36:36.105905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.106815Z",
     "iopub.status.idle": "2024-08-31T17:36:36.107270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.108205Z",
     "iopub.status.idle": "2024-08-31T17:36:36.108607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Assuming testGen and model are defined\n",
    "testGen.reset()\n",
    "y_pred_probs = model.predict(testGen, steps=(totalTest // BATCH_SIZE) + 1)\n",
    "y_true = testGen.classes\n",
    "\n",
    "# Compute ROC curve for the positive class\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.109569Z",
     "iopub.status.idle": "2024-08-31T17:36:36.109947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "testGen.reset()\n",
    "y_pred_probs = model.predict(testGen, steps=(totalTest // BATCH_SIZE) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.110878Z",
     "iopub.status.idle": "2024-08-31T17:36:36.111369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compute predicted class labels\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.112398Z",
     "iopub.status.idle": "2024-08-31T17:36:36.112873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_epoch_vs_accuracy(H, save_path=None):\n",
    "    print(\"Starting to plot...\")  # Debugging print statement\n",
    "    epochs = len(H.history['accuracy'])  # Automatically determine the number of epochs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), H.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(range(1, epochs + 1), H.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Epoch vs Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        \n",
    "    plt.show()\n",
    "    print(\"Plot should be displayed above.\")  # Debugging print statement\n",
    "\n",
    "# Assuming H is defined in your existing code\n",
    "plot_epoch_vs_accuracy(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.113773Z",
     "iopub.status.idle": "2024-08-31T17:36:36.114206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainGen.reset()\n",
    "valGen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.116381Z",
     "iopub.status.idle": "2024-08-31T17:36:36.116833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for layer in baseModel.layers[15:]:\n",
    "\tlayer.trainable = True\n",
    "\n",
    "# loop over the layers in the model and show which ones are trainable\n",
    "# or not\n",
    "for layer in baseModel.layers:\n",
    "\tprint(\"{}: {}\".format(layer, layer.trainable))\n",
    "\n",
    "# for the changes to the model to take affect we need to recompile\n",
    "# the model, this time using SGD with a *very* small learning rate\n",
    "print(\"[INFO] re-compiling model...\")\n",
    "opt = SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.117779Z",
     "iopub.status.idle": "2024-08-31T17:36:36.118231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "H = model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // BATCH_SIZE,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // BATCH_SIZE,\n",
    "\tepochs= epochsFineTune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.119293Z",
     "iopub.status.idle": "2024-08-31T17:36:36.119743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating after fine-tuning network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict_generator(testGen,\n",
    "\tsteps=(totalTest // BATCH_SIZE) + 1)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testGen.classes, predIdxs,\n",
    "\ttarget_names=testGen.class_indices.keys()))\n",
    "plot_training(H, epochsFineTune, UNFROZEN_PLOT_PATH)\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(MODEL_PATH2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.120629Z",
     "iopub.status.idle": "2024-08-31T17:36:36.121027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_epoch_vs_accuracy(H, save_path=None):\n",
    "    print(\"Starting to plot...\")  # Debugging print statement\n",
    "    epochs = len(H.history['accuracy'])  # Automatically determine the number of epochs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), H.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(range(1, epochs + 1), H.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Epoch vs Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        \n",
    "    plt.show()\n",
    "    print(\"Plot should be displayed above.\")  # Debugging print statement\n",
    "\n",
    "# Assuming H is defined in your existing code\n",
    "plot_epoch_vs_accuracy(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.122641Z",
     "iopub.status.idle": "2024-08-31T17:36:36.123035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compute predicted class labels\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-31T17:36:36.123990Z",
     "iopub.status.idle": "2024-08-31T17:36:36.124375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 858837,
     "sourceId": 16880,
     "sourceType": "competition"
    },
    {
     "datasetId": 13405,
     "sourceId": 18147,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 444558,
     "sourceId": 842050,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 451078,
     "sourceId": 893807,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5524489,
     "sourceId": 9146200,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5572420,
     "sourceId": 9215373,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5623570,
     "sourceId": 9289401,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29845,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
